{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML\\\\LiveProject\\\\ML-CreditCardDefaulter\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML\\\\LiveProject\\\\ML-CreditCardDefaulter'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    null_val_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_creditcard_defaulter.constants import *\n",
    "from ml_creditcard_defaulter.utils.common import read_yaml, create_directories, save_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            null_val_path = config.null_val_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from ml_creditcard_defaulter import logger\n",
    "from ml_creditcard_defaulter.utils.common import get_size\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def remove_unwanted_spaces(self,data):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        try:\n",
    "            df_without_spaces = data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)  # drop the labels specified in the columns\n",
    "            logger.info('Unwanted spaces removal Successful.Exited the remove_unwanted_spaces method of the Preprocessor class')\n",
    "            return df_without_spaces\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in remove_unwanted_spaces method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('unwanted space removal Unsuccessful. Exited the remove_unwanted_spaces method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "    def remove_columns(self,data,columns):\n",
    "        try:\n",
    "            useful_data=data.drop(labels=columns, axis=1) # drop the labels specified in the columns\n",
    "            logger.info('Column removal Successful.Exited the remove_columns method of the Preprocessor class')\n",
    "            return useful_data\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in remove_columns method of the Preprocessor class. Exception message:  '+str(e))\n",
    "            logger.info('Column removal Unsuccessful. Exited the remove_columns method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "        \n",
    "    def separate_label_feature(self, data, label_column_name):\n",
    "        try:\n",
    "            X=data.drop(labels=label_column_name,axis=1) # drop the columns specified and separate the feature columns\n",
    "            y=data[label_column_name] # Filter the Label columns\n",
    "            logger.info('Label Separation Successful. Exited the separate_label_feature method of the Preprocessor class')\n",
    "            return X,y\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in separate_label_feature method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('Label Separation Unsuccessful. Exited the separate_label_feature method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "        \n",
    "    def is_null_present(self,data):\n",
    "        null_present = False\n",
    "        cols_with_missing_values=[]\n",
    "        cols = data.columns\n",
    "        try:\n",
    "            null_counts=data.isna().sum() # check for the count of null values per column\n",
    "            for i in range(len(null_counts)):\n",
    "                if null_counts[i]>0:\n",
    "                    null_present=True\n",
    "                    cols_with_missing_values.append(cols[i])\n",
    "            if(null_present): # write the logs to see which columns have null values\n",
    "                dataframe_with_null = pd.DataFrame()\n",
    "                dataframe_with_null['columns'] = data.columns\n",
    "                dataframe_with_null['missing values count'] = np.asarray(data.isna().sum())\n",
    "                dataframe_with_null.to_csv(self.config.null_val_path) # storing the null column information to file\n",
    "            logger.info('Finding missing values is a success.Data written to the null values file. Exited the is_null_present method of the Preprocessor class')\n",
    "            return null_present, cols_with_missing_values\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in is_null_present method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('Finding missing values failed. Exited the is_null_present method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "        \n",
    "    def impute_missing_values(self, data, cols_with_missing_values):\n",
    "        logger.info('Entered the impute_missing_values method of the Preprocessor class')\n",
    "        \n",
    "        cols_with_missing_values=cols_with_missing_values\n",
    "        try:\n",
    "            imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "            for col in cols_with_missing_values:\n",
    "                data[col] = imputer.fit_transform(data[col])\n",
    "            logger.info('Imputing missing values Successful. Exited the impute_missing_values method of the Preprocessor class')\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in impute_missing_values method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('Imputing missing values failed. Exited the impute_missing_values method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "    def scale_numerical_columns(self,data):\n",
    "        logger.info('Entered the scale_numerical_columns method of the Preprocessor class')\n",
    "\n",
    "        try:\n",
    "            num_df = data.select_dtypes(include=['int64']).copy()\n",
    "            scaler = StandardScaler()\n",
    "            scaled_data = scaler.fit_transform(num_df)\n",
    "            scaled_num_df = pd.DataFrame(data=scaled_data, columns=num_df.columns)\n",
    "\n",
    "            logger.info( 'scaling for numerical values successful. Exited the scale_numerical_columns method of the Preprocessor class')\n",
    "            return scaled_num_df\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in scale_numerical_columns method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info( 'scaling for numerical columns Failed. Exited the scale_numerical_columns method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "    def encode_categorical_columns(self,data):\n",
    "        logger.info( 'Entered the encode_categorical_columns method of the Preprocessor class')\n",
    "        try:\n",
    "            cat_df = data.select_dtypes(include=['object']).copy()\n",
    "            # Using the dummy encoding to encode the categorical columns to numericsl ones\n",
    "            for col in cat_df.columns:\n",
    "                cat_df = pd.get_dummies(cat_df, columns=[col], prefix=[col], drop_first=True)\n",
    "\n",
    "            logger.info('encoding for categorical values successful. Exited the encode_categorical_columns method of the Preprocessor class')\n",
    "            return cat_df\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in encode_categorical_columns method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('encoding for categorical columns Failed. Exited the encode_categorical_columns method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "        \n",
    "    def handle_imbalanced_dataset(self,x,y):\n",
    "        logger.info('Entered the handle_imbalanced_dataset method of the Preprocessor class')\n",
    "\n",
    "        try:\n",
    "            rdsmple = RandomOverSampler()\n",
    "            x_sampled,y_sampled  = rdsmple.fit_sample(x,y)\n",
    "            logger.info('dataset balancing successful. Exited the handle_imbalanced_dataset method of the Preprocessor class')\n",
    "            return x_sampled,y_sampled\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in handle_imbalanced_dataset method of the Preprocessor class. Exception message:  ' + str(e))\n",
    "            logger.info('dataset balancing Failed. Exited the handle_imbalanced_dataset method of the Preprocessor class')\n",
    "            raise Exception()\n",
    "        \n",
    "    def elbow_plot(self,data):\n",
    "        logger.info( 'Entered the elbow_plot method of the KMeansClustering class')\n",
    "        wcss=[] # initializing an empty list\n",
    "        try:\n",
    "            for i in range (1,11):\n",
    "                kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42) # initializing the KMeans object\n",
    "                kmeans.fit(data) # fitting the data to the KMeans Algorithm\n",
    "                wcss.append(kmeans.inertia_)\n",
    "            plt.plot(range(1,11),wcss) # creating the graph between WCSS and the number of clusters\n",
    "            plt.title('The Elbow Method')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('WCSS')\n",
    "            #plt.show()\n",
    "            plt.savefig('preprocessing_data/K-Means_Elbow.PNG') # saving the elbow plot locally\n",
    "            # finding the value of the optimum cluster programmatically\n",
    "            kn = KneeLocator(range(1, 11), wcss, curve='convex', direction='decreasing')\n",
    "            logger.info( 'The optimum number of clusters is: '+str(kn.knee)+' . Exited the elbow_plot method of the KMeansClustering class')\n",
    "            return kn.knee\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info('Exception occured in elbow_plot method of the KMeansClustering class. Exception message:  ' + str(e))\n",
    "            logger.info('Finding the number of clusters failed. Exited the elbow_plot method of the KMeansClustering class')\n",
    "            raise Exception()\n",
    "\n",
    "        \n",
    "    def train_test_spliting(self, data):\n",
    "        # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "        # train, test = train_test_split(data)\n",
    "\n",
    "        data.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "\n",
    "\n",
    "        logger.info(\"train data saved\")\n",
    "        logger.info(data.shape)\n",
    "\n",
    "        print(data.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-24 17:52:45,278: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-24 17:52:45,282: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-24 17:52:45,289: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-01-24 17:52:45,289: INFO: common: created directory at: artifacts]\n",
      "[2025-01-24 17:52:45,294: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-01-24 17:52:45,382: INFO: 2505344833: Label Separation Successful. Exited the separate_label_feature method of the Preprocessor class]\n",
      "[2025-01-24 17:52:45,385: INFO: 2505344833: Finding missing values is a success.Data written to the null values file. Exited the is_null_present method of the Preprocessor class]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharif\\AppData\\Local\\Temp\\ipykernel_16548\\2505344833.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if null_counts[i]>0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-24 17:52:45,661: INFO: 2505344833: Splited data into training and test sets]\n",
      "[2025-01-24 17:52:45,662: INFO: 2505344833: (22500, 24)]\n",
      "[2025-01-24 17:52:45,663: INFO: 2505344833: (7500, 24)]\n",
      "(22500, 24)\n",
      "(7500, 24)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data = pd.read_csv(data_transformation_config.data_path)\n",
    "    X, y = data_transformation.separate_label_feature(data,label_column_name='default payment next month')\n",
    "    is_null_present,cols_with_missing_values=data_transformation.is_null_present(X)\n",
    "    if(is_null_present):\n",
    "        X=data_transformation.impute_missing_values(X,cols_with_missing_values)\n",
    "    \n",
    "    X['Labels']=y\n",
    "    data_transformation.train_test_spliting(X)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "i['Labels']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0          20000    2          2         1   24      2      2     -1     -1   \n",
       "1         120000    2          2         2   26     -1      2      0      0   \n",
       "2          90000    2          2         2   34      0      0      0      0   \n",
       "3          50000    2          2         1   37      0      0      0      0   \n",
       "4          50000    1          2         1   57     -1      0     -1      0   \n",
       "...          ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "29995     220000    1          3         1   39      0      0      0      0   \n",
       "29996     150000    1          3         2   43     -1     -1     -1     -1   \n",
       "29997      30000    1          2         2   37      4      3      2     -1   \n",
       "29998      80000    1          3         1   41      1     -1      0      0   \n",
       "29999      50000    1          2         1   46      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -2  ...          0          0          0         0       689   \n",
       "1          0  ...       3272       3455       3261         0      1000   \n",
       "2          0  ...      14331      14948      15549      1518      1500   \n",
       "3          0  ...      28314      28959      29547      2000      2019   \n",
       "4          0  ...      20940      19146      19131      2000     36681   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...      88004      31237      15980      8500     20000   \n",
       "29996      0  ...       8979       5190          0      1837      3526   \n",
       "29997      0  ...      20878      20582      19357         0         0   \n",
       "29998      0  ...      52774      11855      48944     85900      3409   \n",
       "29999      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  Labels  \n",
       "0             0         0         0         0       1  \n",
       "1          1000      1000         0      2000       1  \n",
       "2          1000      1000      1000      5000       0  \n",
       "3          1200      1100      1069      1000       0  \n",
       "4         10000      9000       689       679       0  \n",
       "...         ...       ...       ...       ...     ...  \n",
       "29995      5003      3047      5000      1000       0  \n",
       "29996      8998       129         0         0       0  \n",
       "29997     22000      4200      2000      3100       1  \n",
       "29998      1178      1926     52964      1804       1  \n",
       "29999      1430      1000      1000      1000       1  \n",
       "\n",
       "[30000 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
